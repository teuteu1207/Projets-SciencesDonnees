{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20_HES-SO-ARC_646-2.3 SCIENCE DES DONNÉES\n",
    "## House Prices: Advanced Regression Techniques\n",
    "##### Yanick Christe, Mathieu Stalder, Julien Weideli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En bref, le CRISP-DM est une méthodologie et un modèle de processus complet d'exploration de données qui fournit à tout le monde - des novices aux experts en exploration de données - un plan complet pour mener un projet d'exploration de données. CRISP-DM décompose le cycle de vie d'un projet d'exploration de données en six phases : compréhension de l'entreprise, compréhension des données, préparation des données, modélisation, évaluation et déploiement.\n",
    "\n",
    "**Reference**\n",
    "- Shearer, C. (2000). The CRISP-DM model: the new blueprint for data mining. *Journal of data warehousing*, 5(4), 13-22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each phase of the process:**\n",
    "1. [Business understanding](#Businessunderstanding)\n",
    "    1. [Determine the Business Objectives](#BusinessObjectives)\n",
    "    2. [Assess the Current Situation](#Assessthecurrentsituation)\n",
    "        1. [Inventory of resources](#Inventory)\n",
    "        2. [Requirements, assumptions and constraints](#Requirements)\n",
    "        3. [Risks and contingencies](#Risks)\n",
    "        4. [Terminology](#Terminology)\n",
    "        5. [Costs and benefits](#CostBenefit)\n",
    "    3. [What are the Desired Outputs](#Desiredoutputs)\n",
    "    4. [What Questions Are We Trying to Answer?](#QA)\n",
    "2. [Data Understanding](#Dataunderstanding)\n",
    "    1. [Initial Data Report](#Datareport)\n",
    "    2. [Describe Data](#Describedata)\n",
    "    3. [Initial Data Exploration](#Exploredata) \n",
    "    4. [Verify Data Quality](#Verifydataquality)\n",
    "        1. [Missing Data](#MissingData) \n",
    "        2. [Outliers](#Outliers) \n",
    "    5. [Data Quality Report](#Dataqualityreport)\n",
    "3. [Data Preparation](#Datapreparation)\n",
    "    1. [Select Your Data](#Selectyourdata)\n",
    "    2. [Cleanse the Data](#Cleansethedata)\n",
    "        1. [Label Encoding](#labelEncoding)\n",
    "        2. [Drop Unnecessary Columns](#DropCols)\n",
    "        3. [Altering Datatypes](#AlteringDatatypes)\n",
    "        4. [Dealing With Zeros](#DealingZeros)\n",
    "    3. [Construct Required Data](#Constructrequireddata)\n",
    "    4. [Integrate Data](#Integratedata)\n",
    "4. [Exploratory Data Analysis](#EDA)\n",
    "5. [Modelling](#Modelling)\n",
    "    1. [Modelling Technique](#ModellingTechnique)\n",
    "    2. [Modelling Assumptions](#ModellingAssumptions)\n",
    "    3. [Build Model](#BuildModel)\n",
    "    4. [Assess Model](#AssessModel)\n",
    "6. [Evaluation](#Evaluation)\n",
    "    1. [Evaluate Results](#EvaluateResults)\n",
    "    2. [Review Process](#ReviewProcess)\n",
    "    3. [Determine Next Steps](#NextSteps)\n",
    "7. [Deployment](#Deployment)\n",
    "    1. [Plan Deployment](#PlanDeployment)\n",
    "    2. [Plan Monitoring and Maintenance](#Monitoring)\n",
    "    3. [Produce Final Report](#FinalReport)\n",
    "    4. [Review Project](#ReviewProject)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compréhension du métier  <a class=\"anchor\" id=\"Businessunderstanding\"></a>\n",
    "Le domaine immobilier est très vaste, il comporte deux activités principale. La location de biens et la vente de biens, dans ce travail nous allons nous intéresser uniquement au côté des ventes. \n",
    "\n",
    "Certaines règles peuvent paraître logique si vous avez déjà fait la démarche d'acheter une maison. Il est possible de faire une liste d'éléments qui peuvent influencer le prix, par exemple une maison avec un jardin, peut-être plus cher qu'une maison ne disposant pas de jardin. D'autres aspects comme l'emplacement entre le centre d'une ville et la campagne, la proximité avec des magasins bus etc... , le nombre de chambres, la superficie peuvent influencer les prix. Mais est-ce vraiment le cas? Certains paramètres pèsent-ils plus dans la balance que d'autres?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Déterminer les objectifs métier <a class=\"anchor\" id=\"BusinessObjectives\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce travail est de déterminer se qui peut influencer le prix de biens immobiliers. Il est aussi possible d'établir une liste d'éléments qui n'influence absoluement pas le prix d'un bien afin de ne pas prendre en compte ces paramètres plus tard. Pour cela un dataset est fourni et permet en fonction de données de faire ressortir ces différentes informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation de la situation actuelle <a class=\"anchor\" id=\"Assessthecurrentsituation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce projet les données de bases viennent d'une compétition Kaggle \"House Prices: Advanced Regression Techniques\". Dans le chapitre suivant le dataset sera détaillé, mais afin d'établir une base, il est composé de paramètres qui peuvent potentiellement influencer le prix d'une maison. C'est une liste de différents biens immobiliers ainsi que des paramètres comme la superficie, si elle possède un jardin, combien de places de voiture il-y-a dans le garage etc. Comme ceci est un \"exercice\", le projet n'a pas de risques financier, en revanche notre note est un risque. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Inventaire des resources <a class=\"anchor\" id=\"Inventory\"></a>\n",
    "Ci-dessous la liste des ressources à disposition pour résoudre la problématique de ce projet\n",
    "- Personnel: 3 étudiants (Mathieu Stalder, Julien Weideli, Yanick Christe)\n",
    "- Data: Le dataset mis à disposition sur kaggle (House Prices)\n",
    "- Software: Utilisation de Jupyter Notebook\n",
    "- Langage : Nous utiliserons pour ce projet le Python en version 3\n",
    "- Outils : Nous utiliserons la plateforme GIT pour le partage des différents documents\n",
    "- Communication : Dans la situation actuelle, Teams est utilisé pour la communication avec l'équipe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Requirements, assumptions and constraints <a class=\"anchor\" id=\"Requirements\"></a> \n",
    "- Requirements of the project including the schedule of completion\n",
    "- Required comprehensibility and quality of results\n",
    "- Data security concerns as well as any legal issues. \n",
    "- Assumptions made by the project. These may be assumptions about the data that can be verified during data mining, but may also include non-verifiable assumptions about the business related to the project. It is particularly important to list the latter if they will affect the validity of the results. \n",
    "- List the constraints on the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Risks and contingencies <a class=\"anchor\" id=\"Risks\"></a>\n",
    "- List the risks or events that might delay the project or cause it to fail. \n",
    "- what action will you take if these risks or events take place? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Terminology <a class=\"anchor\" id=\"Terminology\"></a>\n",
    "- A glossary of relevant business terminology\n",
    "- A glossary of data mining terminology, illustrated with examples relevant to the business problem in question. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Costs and benefits  <a class=\"anchor\" id=\"CostBenefit\"></a>\n",
    "- Construct a cost-benefit analysis for the project which compares the costs of the project with the potential benefits to the business if it is successful. This comparison should be as specific as possible. For example, you should use financial measures in a commercial situation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.3 What are the desired outputs of the project? <a class=\"anchor\" id=\"Desiredoutputs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Business success criteria**\n",
    "- \n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "**Data mining success criteria**\n",
    "- \n",
    "- \n",
    "\n",
    "\n",
    "**Produce project plan**\n",
    "- \n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.4 What Questions Are We Trying To Answer? <a class=\"anchor\" id=\"QA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compréhension de données <a class=\"anchor\" id=\"Dataunderstanding\"></a>\n",
    "La phase de compréhension des données commence par une première collecte de données. L'analyste procède ensuite à une meilleure connaissance des données, à l'identification des problèmes de qualité des données, à la découverte des premiers aperçus des données ou à la détection de sous-ensembles intéressants pour former des hypothèses sur les informations cachées. La phase de compréhension des données comporte quatre étapes, dont la collecte des données initiales, la description des données, l'exploration des données et la vérification de la qualité des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Rapport sur les données initiales <a class=\"anchor\" id=\"Datareport\"></a>\n",
    "Rapport sur la collecte initiale de données - \n",
    "Énumérez les sources de données acquises avec leur localisation, les méthodes utilisées pour les acquérir et les problèmes éventuels rencontrés. Enregistrez les problèmes rencontrés et les solutions obtenues. Cela permettra de reproduire ce projet à l'avenir et d'exécuter des projets similaires à l'avenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries Required\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data source: \n",
    "#Source Query location: \n",
    "path =  'train.csv'\n",
    "# reads the data from the file - denotes as CSV, it has no header, sets column headers\n",
    "df =  pd.read_csv(path, sep=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Décrire les données <a class=\"anchor\" id=\"Describedata\"></a>\n",
    "Rapport de description des données - Décrivez les données qui ont été acquises, y compris leur format, leur quantité (par exemple, le nombre d'enregistrements et de champs dans chaque tableau), l'identité des champs et toute autre caractéristique de surface qui a été découverte. Évaluez si les données acquises répondent à vos exigences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 int64\n",
       "MSSubClass         int64\n",
       "MSZoning          object\n",
       "LotFrontage      float64\n",
       "LotArea            int64\n",
       "                  ...   \n",
       "MoSold             int64\n",
       "YrSold             int64\n",
       "SaleType          object\n",
       "SaleCondition     object\n",
       "SalePrice          int64\n",
       "Length: 81, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Vérifier la qualité des données <a class=\"anchor\" id=\"Verifydataquality\"></a>\n",
    "\n",
    "Examiner la qualité des données, en abordant des questions telles que\n",
    "\n",
    "- Les données sont-elles complètes (couvrent-elles tous les cas requis) ?\n",
    "- Sont-elles correctes ou contiennent-elles des erreurs et, si elles existent, quelle est leur fréquence ?\n",
    "- Y a-t-il des valeurs manquantes dans les données ? Dans l'affirmative, comment sont-elles représentées, où se trouvent-elles et dans quelle mesure sont-elles courantes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Données manquantes <a class=\"anchor\" id=\"MissingData\"></a>\n",
    "En plus des types de données incorrects, un autre problème courant lors du traitement des données du monde réel est l'absence de valeurs. Celles-ci peuvent survenir pour de nombreuses raisons et doivent être soit remplies, soit supprimées avant que nous ne formions un modèle d'apprentissage machine. Tout d'abord, voyons combien de valeurs manquent dans chaque colonne \n",
    "\n",
    "Bien que nous voulions toujours faire attention à la suppression d'informations, si une colonne comporte un pourcentage élevé de valeurs manquantes, elle ne sera probablement pas utile à notre modèle. Le seuil de suppression des colonnes devrait dépendre du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns with > 50% missing\n",
    "missing_df = missing_values_table(df);\n",
    "missing_columns = list(missing_df[missing_df['% of Total Values'] > 50].index)\n",
    "print('We will remove %d columns.' % len(missing_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "df = df.drop(list(missing_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Valeurs aberrantes <a class=\"anchor\" id=\"Outliers\"></a>\n",
    "À ce stade, nous pourrions également vouloir supprimer les valeurs aberrantes. Celles-ci peuvent être dues à des fautes de frappe dans la saisie des données, à des erreurs dans les unités ou à des valeurs légitimes mais extrêmes. Pour ce projet, nous supprimerons les anomalies en nous basant sur la définition des valeurs aberrantes extrêmes :\n",
    "\n",
    "https://en.wikipedia.org/wiki/Outlier\n",
    "\n",
    "- En dessous du premier quartile - 3 ∗ interquartile\n",
    "- Au-dessus du troisième quartile + 3 ∗ intervalle interquartile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Exploration initiale des données  <a class=\"anchor\" id=\"Exploredata\"></a>\n",
    "Au cours de cette étape, vous aborderez les questions d'exploration de données en utilisant des techniques d'interrogation, de visualisation des données et de rapport. Ces techniques peuvent comprendre :\n",
    "\n",
    "- **Distribution** d'attributs clés (par exemple, l'attribut cible d'une tâche de prédiction)\n",
    "- **Relations** entre paires ou petit nombre d'attributs\n",
    "- Résultats des **agrégations simples**\n",
    "- **Propriétés** de sous-populations importantes\n",
    "- **Simple** analyses statistiques\n",
    "\n",
    "Ces analyses peuvent répondre directement à vos objectifs d'exploration de données. Elles peuvent également contribuer ou affiner la description des données et les rapports de qualité, et alimenter la transformation et les autres étapes de préparation des données nécessaires à une analyse plus approfondie. \n",
    "\n",
    "- **Rapport d'exploration de données** - Décrivez les résultats de votre exploration de données, y compris les premiers résultats ou l'hypothèse initiale et leur impact sur le reste du projet. Le cas échéant, vous pouvez inclure des graphiques et des tracés ici pour indiquer les caractéristiques des données qui suggèrent un examen plus approfondi de sous-ensembles de données intéressants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Distributions  <a class=\"anchor\" id=\"Distributions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values_table(df):\n",
    "        count_val = df.value_counts()\n",
    "        count_val_percent = 100 * df.value_counts() / len(df)\n",
    "        count_val_table = pd.concat([count_val, count_val_percent.round(1)], axis=1)\n",
    "        count_val_table_ren_columns = count_val_table.rename(\n",
    "        columns = {0 : 'Count Values', 1 : '% of Total Values'})\n",
    "        return count_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "def hist_chart(df, col):\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        plt.hist(df[col].dropna(), edgecolor = 'k');\n",
    "        plt.xlabel(col); plt.ylabel('Number of Entries'); \n",
    "        plt.title('Distribution of '+col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'account_risk_band'\n",
    "# Histogram & Results\n",
    "hist_chart(df, col)\n",
    "count_values_table(df.account_risk_band)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Corrélations  <a class=\"anchor\" id=\"Correlations\"></a>\n",
    "Pouvons-nous déduire une quelconque corrélation de cet ensemble de données. Le graphique en paires nous donne les corrélations, les distributions et le chemin de régression\n",
    "Les corrélogrammes sont géniaux pour l'analyse exploratoire. Il permet d'observer rapidement la relation entre chaque variable de votre matrice. \n",
    "Il est facile de le faire avec Seaborn : il suffit d'appeler la fonction de couplage\n",
    "\n",
    "Le taxi de la documentation sur les parcelles en couple se trouve ici : https://seaborn.pydata.org/generated/seaborn.pairplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seaborn allows to make a correlogram or correlation matrix really easily. \n",
    "#sns.pairplot(df.dropna().drop(['x'], axis=1), hue='y', kind ='reg')\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_agg = df.drop(['x'], axis=1).groupby(['y']).sum()\n",
    "df_agg = df.groupby(['y']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Différenciation\n",
    "Plus précisément, une nouvelle série est construite où la valeur au pas de temps actuel est calculée comme la différence entre l'observation originale et l'observation au pas de temps précédent.\n",
    "valeur(t) = observation(t) - observation(t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dif_agg = df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differencing\n",
    "#Specifically, a new series is constructed where the value at the current time step is calculated \n",
    "#as the difference between the original observation and the observation at the previous time step.\n",
    "#value(t) = observation(t) - observation(t-1)\n",
    "df_dif = df_dif_agg.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Rapport sur la qualité des données <a class=\"anchor\" id=\"Dataqualityreport\"></a>\n",
    "Liste des résultats de la vérification de la qualité des données. Si des problèmes de qualité existent, proposez des solutions possibles. Les solutions aux problèmes de qualité des données dépendent généralement beaucoup des données et de la connaissance des entreprises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Préparation des données <a class=\"anchor\" id=\"Datapreparation\"></a>\n",
    "C'est l'étape du projet où vous décidez des données que vous allez utiliser pour l'analyse. Les critères que vous pourriez utiliser pour prendre cette décision doivent comprendre la pertinence des données par rapport à vos objectifs d'exploration de données, la qualité des données, ainsi que les contraintes techniques telles que les limites sur le volume ou les types de données. Notez que la sélection des données couvre la sélection des attributs (colonnes) ainsi que la sélection des enregistrements (lignes) dans un tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Sélection des données <a class=\"anchor\" id=\"Selectyourdata\"></a>\n",
    "C'est l'étape du projet où vous décidez des données que vous allez utiliser pour l'analyse. Les critères que vous pourriez utiliser pour prendre cette décision comprennent la pertinence des données par rapport à vos objectifs d'exploration de données, la qualité des données, ainsi que les contraintes techniques telles que les limites sur le volume ou les types de données. Notez que la sélection des données couvre la sélection des attributs (colonnes) ainsi que la sélection des enregistrements (lignes) dans un tableau.\n",
    "\n",
    "Justification de l'inclusion/exclusion - Indiquez les données à inclure/exclure et les raisons de ces décisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regr = df.drop(['date_maint', 'account_open_date'], axis = 1)\n",
    "X_train = df.drop(['target', 'date_maint', 'account_open_date'], axis = 1)\n",
    "X_test = test.drop(['date_maint', 'account_open_date'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Nettoyer les données <a class=\"anchor\" id=\"Cleansethedata\"></a>\n",
    "Cette tâche consiste à élever la qualité des données au niveau requis par les techniques d'analyse que vous avez sélectionnées. Cela peut impliquer la sélection de sous-ensembles de données propres, l'insertion de valeurs par défaut appropriées, ou des techniques plus ambitieuses telles que l'estimation des données manquantes par modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Encodage des étiquettes <a class=\"anchor\" id=\"labelEncoding\"></a>\n",
    "Encodage des étiquettes pour transformer les valeurs catégorielles en nombres entiers\n",
    "\n",
    "Une approche de l'encodage des valeurs catégorielles consiste à utiliser une technique appelée encodage des étiquettes. L'encodage par étiquette consiste simplement à convertir chaque valeur d'une colonne en un nombre. Par exemple, la colonne body_style contient 5 valeurs différentes. Nous pourrions choisir de l'encoder de cette manière :\n",
    "\n",
    "convertible -> 0\n",
    "hardtop -> 1\n",
    "hatchback -> 2\n",
    "berline -> 3\n",
    "wagon -> 4\n",
    "http://pbpython.com/categorical-encoding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "for col in CAT_COLS:\n",
    "        encoder = LabelEncoder()\n",
    "        X_train[col] = encoder.fit_transform(X_train[col].astype(str))\n",
    "        X_test[col] = encoder.transform(X_test[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"column\"] = df[\"column\"].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"column\"] = df[\"column\"].cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Suppression des Colonnes pas nécessaires <a class=\"anchor\" id=\"DropCols\"></a>\n",
    "Parfois, nous n'avons pas besoin de certaines colonnes. Nous pouvons juste garder les données pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_col_list = ['col1', 'col2']\n",
    "\n",
    "df = df.drop(del_col_list, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Modification des types de données <a class=\"anchor\" id=\"AlteringDatatypes\"></a>\n",
    "Parfois, il peut être nécessaire de modifier les types de données. Y compris les types de données d'objets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire face aux zéros <a class=\"anchor\" id=\"DealingZeros\"></a>\n",
    "Remplacement de tous les zéros des cols. **Note** ajouter / supprimer selon les besoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['col1', 'col2']\n",
    "#df[cols] = df[cols].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all the rows with na in the columns mentioned above in the list.\n",
    "\n",
    "# df.dropna(subset=cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 Faire face aux duplications <a class=\"anchor\" id=\"DealingDuplicates\"></a>\n",
    "Supprimer les lignes en double. **Note** : ajouter / supprimer selon les besoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Construire les données requises   <a class=\"anchor\" id=\"Constructrequireddata\"></a>\n",
    "Cette tâche comprend des opérations constructives de préparation des données, telles que la production d'attributs dérivés ou de nouveaux enregistrements entiers, ou de valeurs transformées pour des attributs existants.\n",
    "\n",
    "**Attributs dérivés** - Il s'agit de nouveaux attributs qui sont construits à partir d'un ou plusieurs attributs existants dans le même enregistrement. Par exemple, vous pouvez utiliser les variables de longueur et de largeur pour calculer une nouvelle variable de surface.\n",
    "\n",
    "**Enregistrements générés** - Vous décrivez ici la création de tout enregistrement complètement nouveau. Par exemple, vous pouvez avoir besoin de créer des enregistrements pour les clients qui n'ont fait aucun achat au cours de l'année écoulée. Il n'y a aucune raison d'avoir de tels enregistrements dans les données brutes, mais à des fins de modélisation, il peut être utile de représenter explicitement le fait que certains clients n'ont effectué aucun achat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Integration des Données  <a class=\"anchor\" id=\"Integratedata\"></a>\n",
    "Il s'agit de méthodes par lesquelles des informations sont combinées à partir de plusieurs bases de données, tables ou enregistrements pour créer de nouveaux enregistrements ou valeurs.\n",
    "\n",
    "**Données fusionnées** - La fusion de tables fait référence à la réunion de deux ou plusieurs tables qui contiennent des informations différentes sur les mêmes objets. Par exemple, une chaîne de vente au détail peut avoir un tableau contenant des informations sur les caractéristiques générales de chaque magasin (par exemple, la superficie, le type de centre commercial), un autre tableau contenant des données résumées sur les ventes (par exemple, le bénéfice, le pourcentage de variation des ventes par rapport à l'année précédente), et un autre contenant des informations sur la démographie de la région environnante. Chacun de ces tableaux contient un enregistrement pour chaque magasin. Ces tableaux peuvent être fusionnés en un nouveau tableau contenant un enregistrement pour chaque magasin, en combinant les champs des tableaux sources.\n",
    "\n",
    "**Aggrégations** - Les agrégations font référence aux opérations dans lesquelles de nouvelles valeurs sont calculées en résumant les informations de plusieurs enregistrements et/ou tables. Par exemple, la conversion d'une table d'achats de clients où il y a un enregistrement pour chaque achat en une nouvelle table où il y a un enregistrement pour chaque client, avec des champs tels que le nombre d'achats, le montant moyen des achats, le pourcentage de commandes facturées par carte de crédit, le pourcentage d'articles en promotion, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire notre premier Data Set\n",
    "Join data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis <a class=\"anchor\" id=\"EDA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset has been prepared, you'll need to analyze it and summarize it's main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modelling <a class=\"anchor\" id=\"Modelling\"></a>\n",
    "As the first step in modelling, you'll select the actual modelling technique that you'll be using. Although you may have already selected a tool during the business understanding phase, at this stage you'll be selecting the specific modelling technique e.g. decision-tree building with C5.0, or neural network generation with back propagation. If multiple techniques are applied, perform this task separately for each technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Modelling technique <a class=\"anchor\" id=\"ModellingTechnique\"></a>\n",
    "Document the actual modelling technique that is to be used.\n",
    "\n",
    "Import Models below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Modelling assumptions <a class=\"anchor\" id=\"ModellingAssumptions\"></a>\n",
    "Many modelling techniques make specific assumptions about the data, for example that all attributes have uniform distributions, no missing values allowed, class attribute must be symbolic etc. Record any assumptions made.\n",
    "\n",
    "- \n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Build Model <a class=\"anchor\" id=\"BuildModel\"></a>\n",
    "Run the modelling tool on the prepared dataset to create one or more models.\n",
    "\n",
    "**Parameter settings** - With any modelling tool there are often a large number of parameters that can be adjusted. List the parameters and their chosen values, along with the rationale for the choice of parameter settings.\n",
    "\n",
    "**Models** - These are the actual models produced by the modelling tool, not a report on the models.\n",
    "\n",
    "**Model descriptions** - Describe the resulting models, report on the interpretation of the models and document any difficulties encountered with their meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Assess Model <a class=\"anchor\" id=\"AssessModel\"></a>\n",
    "Interpret the models according to your domain knowledge, your data mining success criteria and your desired test design. Judge the success of the application of modelling and discovery techniques technically, then contact business analysts and domain experts later in order to discuss the data mining results in the business context. This task only considers models, whereas the evaluation phase also takes into account all other results that were produced in the course of the project.\n",
    "\n",
    "At this stage you should rank the models and assess them according to the evaluation criteria. You should take the business objectives and business success criteria into account as far as you can here. In most data mining projects a single technique is applied more than once and data mining results are generated with several different techniques. \n",
    "\n",
    "**Model assessment** - Summarise the results of this task, list the qualities of your generated models (e.g.in terms of accuracy) and rank their quality in relation to each other.\n",
    "\n",
    "**Revised parameter settings** - According to the model assessment, revise parameter settings and tune them for the next modelling run. Iterate model building and assessment until you strongly believe that you have found the best model(s). Document all such revisions and assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation <a class=\"anchor\" id=\"Evaluation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to final deployment of the model built by the data analyst, it is important to more thoroughly evaluate the model and review the model’s construction to be certain it properly achieves the business objectives. Here it is critical to determine if some important business issue has not been sufficiently considered. At the end of this phase, the project leader then should decide exactly how to use the data mining results. The key steps here are the evaluation of results, the process review, and the determination of next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Evaluate Results <a class=\"anchor\" id=\"EvaluateResults\"></a>\n",
    "\n",
    "Previous evaluation steps dealt with factors such as the accuracy and generality of the model. This step assesses the degree to which the model meets the business objectives and determines if there is some business reason why this model is deficient. Another option here is to test the model(s) on real-world applications—if time and budget constraints permit. Moreover, evaluation also seeks to unveil additional challenges, information, or hints for future directions.\n",
    "\n",
    "At this stage, the data analyst summarizes the assessment results in terms of business success criteria, including a final statement about whether the project already meets the initial\n",
    "business objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Review Process <a class=\"anchor\" id=\"ReviewProcess\"></a>\n",
    "\n",
    "It is now appropriate to do a more thorough review of the data mining engagement to determine if there is any important factor or task that has somehow been overlooked. This review also covers quality assurance issues (e.g., did we correctly build the model? Did we only use allowable attributes that are available for future deployment?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Determine Next Steps <a class=\"anchor\" id=\"NextSteps\"></a>\n",
    "\n",
    "At this stage, the project leader must decide whether to finish this project and move on to deployment or whether to initiate further iterations or set up new data mining projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Deployment  <a class=\"anchor\" id=\"Deployment\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model creation is generally not the end of the project. The knowledge gained must be organized and presented in a way that the customer can use it, which often involves applying “live” models within an organization’s decision-making processes, such as the real-time personalization of Web pages or repeated scoring of marketing databases.\n",
    "\n",
    "Depending on the requirements, the deployment phase can be as simple as generating a report or as complex as implementing a repeatable data mining process across the enterprise. Even though it is often the customer, not the data analyst, who carries out the deployment steps, it is important for the customer to understand up front what actions must be taken in order to actually make use of the created models. The key steps here are plan deployment, plan monitoring and maintenance, the production of the final report, and review of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Plan Deployment <a class=\"anchor\" id=\"PlanDeployment\"></a>\n",
    "\n",
    "In order to deploy the data mining result(s) into the business, this task takes the evaluation results and develops a strategy for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Plan Monitoring and Maintenance <a class=\"anchor\" id=\"Monitoring\"></a>\n",
    "Monitoring and maintenance are important issues if the data mining result is to become part of the day-to-day business and its environment. A carefully prepared maintenance strategy avoids incorrect usage of data mining results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Produce Final Report <a class=\"anchor\" id=\"FinalReport\"></a>\n",
    "At the end of the project, the project leader and his or her team write up a final report. Depending on the deployment plan, this report may be only a summary of the project and its experiences (if they have not already been documented as an ongoing activity) or it may be a final and comprehensive presentation of the data mining result(s). This report includes all of the previous deliverables and summarizes and organizes the results. Also, there often will be a meeting at the conclusion of the project, where the results are verbally presented to the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Review Project <a class=\"anchor\" id=\"ReviewProject\"></a>\n",
    "The data analyst should assess failures and successes as well as potential areas of improvement for use in future projects. This step should include a summary of important experiences during the project and can include interviews with the significant project participants. This document could include pitfalls, misleading approaches, or hints for selecting the best-suited data mining techniques in similar situations. In ideal projects, experience documentation also covers any reports written by individual project members during the project phases and tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
